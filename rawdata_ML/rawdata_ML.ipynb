{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中证A50成分股\n",
    "# 信息来源：东方财富 20250324\n",
    "code_list = [\n",
    "    '688981sh', '603993sh', '603259sh', '601899sh', '601888sh', \n",
    "    '601816sh', '601766sh', '601668sh', '601600sh', '601318sh', \n",
    "    '601088sh', '601012sh', '600900sh', '600893sh',     # 中国移动2022年上市，暂时没有相关数据\n",
    "    '600887sh', '600660sh', '600585sh', '600519sh', '600436sh', \n",
    "    '600426sh', '600415sh', '600406sh', '600309sh', '600276sh', \n",
    "    '600176sh', '600036sh', '600031sh', '600030sh', '600028sh', \n",
    "    '600019sh', '600009sh', '300760sz', '300750sz', '300408sz', \n",
    "    '300124sz', '300122sz', '300015sz', '002714sz', '002594sz', \n",
    "    '002475sz', '002371sz', '002230sz', '002027sz', '000938sz', \n",
    "    '000792sz', '000725sz', '000333sz', '000063sz', '000002sz'\n",
    "    ]  \n",
    "\n",
    "REC_CNT = 10\n",
    "PRED_CNT = 5\n",
    "IS_BINARY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_new_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算新特征\n",
    "    \"\"\"\n",
    "    df['mid_price'] = (df['BidPr1'] + df['AskPr1']) / 2\n",
    "    df['TWAP_mid_price'] = df['mid_price'].rolling(window=PRED_CNT).mean()\n",
    "    \n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def calc_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算标签\n",
    "    \"\"\"\n",
    "    df['label'] = 0\n",
    "    if IS_BINARY:\n",
    "        df['label'] = np.where(df['TWAP_mid_price'].shift(-PRED_CNT) > df['mid_price'], 1, 0)\n",
    "    # TODO: else:\n",
    "    return df\n",
    "\n",
    "def single_entry_gen(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    生成单条数据样本\n",
    "    \"\"\"\n",
    "    snapshots_df = df.copy().reset_index(drop=True)\n",
    "    base_price = snapshots_df['mid_price'].iloc[0]\n",
    "    for level in range(1, 6):  # relative price\n",
    "        snapshots_df[f'BidPr{level}'] = snapshots_df[f'BidPr{level}'] / base_price - 1\n",
    "        snapshots_df[f'AskPr{level}'] = snapshots_df[f'AskPr{level}'] / base_price - 1\n",
    "    # TODO: 其他特征\n",
    "    \n",
    "    used_cols = []\n",
    "    for level in range(1, 6):\n",
    "        used_cols.append(f'BidPr{level}')\n",
    "        used_cols.append(f'BidVol{level}')\n",
    "        used_cols.append(f'AskPr{level}')\n",
    "        used_cols.append(f'AskVol{level}')\n",
    "    \n",
    "    X = snapshots_df.loc[:REC_CNT, used_cols].copy()  # rolling window\n",
    "    X = X.values.flatten()\n",
    "    # TODO：X 增加一些特征，比如时间、股票代码等\n",
    "    y = snapshots_df['label'].iloc[REC_CNT-1].copy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9482/9482 [00:21<00:00, 445.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688981sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9471/9471 [00:20<00:00, 456.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603993sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9460/9460 [00:20<00:00, 456.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603259sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9460/9460 [00:20<00:00, 454.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601899sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4726/4726 [00:10<00:00, 457.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601888sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9502/9502 [00:20<00:00, 456.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601816sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:20<00:00, 456.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601766sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9475/9475 [00:20<00:00, 457.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601668sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9460/9460 [00:20<00:00, 456.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601600sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9461/9461 [00:20<00:00, 456.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601318sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9468/9468 [00:20<00:00, 456.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601088sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9461/9461 [00:20<00:00, 457.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601012sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9473/9473 [00:20<00:00, 458.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600900sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9465/9465 [00:20<00:00, 456.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600893sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9462/9462 [00:20<00:00, 457.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600887sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9465/9465 [00:20<00:00, 455.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600660sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9470/9470 [00:20<00:00, 457.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600585sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9499/9499 [00:20<00:00, 452.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9469/9469 [00:20<00:00, 456.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600436sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9466/9466 [00:20<00:00, 451.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600426sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9484/9484 [00:20<00:00, 454.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600415sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9473/9473 [00:20<00:00, 456.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600406sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9461/9461 [00:21<00:00, 436.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600309sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9461/9461 [00:21<00:00, 435.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600276sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9460/9460 [00:21<00:00, 443.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600176sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9460/9460 [00:21<00:00, 448.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600036sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9460/9460 [00:20<00:00, 459.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600031sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9461/9461 [00:21<00:00, 446.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600030sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9470/9470 [00:22<00:00, 426.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600028sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9462/9462 [00:22<00:00, 424.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600019sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9486/9486 [00:21<00:00, 435.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600009sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9446/9446 [00:21<00:00, 429.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300760sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:23<00:00, 397.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300750sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9360/9360 [00:22<00:00, 424.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300408sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:21<00:00, 440.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300124sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:20<00:00, 455.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300122sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:21<00:00, 445.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300015sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:21<00:00, 445.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002714sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:21<00:00, 443.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002594sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:20<00:00, 454.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002475sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [00:21<00:00, 436.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002371sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9454/9454 [00:22<00:00, 413.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002230sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:22<00:00, 414.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002027sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9452/9452 [00:22<00:00, 426.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000938sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:21<00:00, 444.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000792sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:20<00:00, 457.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000725sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:20<00:00, 459.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000333sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:20<00:00, 455.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000063sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9457/9457 [00:21<00:00, 438.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000002sz.csv loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((458928, 200),\n",
       " (458928, 1),\n",
       " label\n",
       " 0    0.633958\n",
       " 1    0.366042\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df\n",
    "\n",
    "folder_path = '../data_202111'\n",
    "\n",
    "X_df_list = []\n",
    "y_df_list = []\n",
    "for code in code_list:\n",
    "    # df = _U.get_stock_data(code, start_date='2021-11-1', end_date='2021-11-2')\n",
    "    df = pd.read_csv(f'{folder_path}/{code}.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df[(df['datetime'] >= '2021-11-1 00:00:00') & (df['datetime'] <= '2021-11-2 23:59:59')]  # 初步只取\n",
    "    \n",
    "    df = calc_new_features(df)\n",
    "    df = calc_labels(df)\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for i in tqdm.tqdm(range(len(df) - (REC_CNT + PRED_CNT))):\n",
    "        single_X, single_y = single_entry_gen(df.iloc[i:i + REC_CNT])\n",
    "        X_list.append(single_X)\n",
    "        y_list.append(single_y)\n",
    "    \n",
    "    X_df = pd.DataFrame(X_list)\n",
    "    y_df = pd.DataFrame(y_list)\n",
    "    \n",
    "    used_cols = []\n",
    "    for level in range(1, 6):\n",
    "        used_cols.append(f'BidPr{level}')\n",
    "        used_cols.append(f'BidVol{level}')\n",
    "        used_cols.append(f'AskPr{level}')\n",
    "        used_cols.append(f'AskVol{level}')\n",
    "    col_list = []\n",
    "    for i in range(1, REC_CNT):\n",
    "        for col in used_cols:\n",
    "            col_list.append(f'{col}_lag{i}')\n",
    "    # print(f'X cols: {used_cols + col_list}')\n",
    "    if len(X_df) == 0:\n",
    "        print(f'{code}.csv empty.')\n",
    "        continue\n",
    "\n",
    "    if len(X_df.columns) != len(used_cols + col_list):\n",
    "        raise ValueError(f'X_df columns length mismatch: {len(X_df.columns)} != {len(used_cols + col_list)}')\n",
    "    X_df.columns = used_cols + col_list\n",
    "    y_df.columns = ['label']\n",
    "    \n",
    "    X_df_list.append(X_df)\n",
    "    y_df_list.append(y_df)\n",
    "    print(f'{code}.csv loaded.')\n",
    "    \n",
    "train_X_df = pd.concat(X_df_list, axis=0)\n",
    "train_y_df = pd.concat(y_df_list, axis=0)\n",
    "train_X_df.dropna(axis=0, inplace=True)\n",
    "train_y_df.dropna(axis=0, inplace=True)\n",
    "train_X_df.reset_index(drop=True, inplace=True)\n",
    "train_y_df.reset_index(drop=True, inplace=True)\n",
    "train_X_df.shape, train_y_df.shape, train_y_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14239/14239 [00:32<00:00, 444.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688981sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14210/14210 [00:34<00:00, 416.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603993sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14207/14207 [00:31<00:00, 449.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603259sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14201/14201 [00:32<00:00, 440.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601899sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14212/14212 [00:30<00:00, 460.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601888sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14139/14139 [00:30<00:00, 457.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601816sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14257/14257 [00:31<00:00, 458.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601766sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14248/14248 [00:31<00:00, 445.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601668sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14203/14203 [00:42<00:00, 330.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601600sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14204/14204 [00:34<00:00, 413.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601318sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14226/14226 [00:34<00:00, 416.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601088sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14201/14201 [00:34<00:00, 412.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601012sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14239/14239 [00:34<00:00, 416.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600900sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14209/14209 [00:34<00:00, 417.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600893sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14201/14201 [00:32<00:00, 436.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600887sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14218/14218 [00:32<00:00, 434.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600660sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14265/14265 [00:33<00:00, 423.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600585sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14256/14256 [00:33<00:00, 424.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14237/14237 [00:33<00:00, 427.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600436sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14233/14233 [00:32<00:00, 431.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600426sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14183/14183 [00:33<00:00, 427.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600415sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14243/14243 [00:32<00:00, 436.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600406sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14208/14208 [00:33<00:00, 423.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600309sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14202/14202 [00:31<00:00, 448.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600276sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14231/14231 [00:33<00:00, 428.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600176sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14207/14207 [00:32<00:00, 442.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600036sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14200/14200 [00:31<00:00, 457.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600031sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14207/14207 [00:33<00:00, 429.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600030sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14232/14232 [00:32<00:00, 442.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600028sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14226/14226 [00:31<00:00, 446.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600019sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14226/14226 [00:31<00:00, 450.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600009sh.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14174/14174 [00:31<00:00, 453.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300760sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:30<00:00, 460.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300750sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13972/13972 [00:30<00:00, 458.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300408sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:31<00:00, 456.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300124sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14190/14190 [00:32<00:00, 441.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300122sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:30<00:00, 458.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300015sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:31<00:00, 457.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002714sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:31<00:00, 454.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002594sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:30<00:00, 457.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002475sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14157/14157 [00:32<00:00, 435.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002371sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14194/14194 [00:31<00:00, 446.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002230sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:31<00:00, 448.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002027sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14146/14146 [00:31<00:00, 448.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000938sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14193/14193 [00:30<00:00, 461.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000792sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:31<00:00, 457.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000725sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:31<00:00, 451.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000333sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:32<00:00, 438.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000063sz.csv loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14195/14195 [00:33<00:00, 423.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000002sz.csv loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((695941, 200),\n",
       " (695941, 1),\n",
       " label\n",
       " 0    0.644467\n",
       " 1    0.355533\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df\n",
    "\n",
    "folder_path = '../data_202111'\n",
    "\n",
    "X_df_list = []\n",
    "y_df_list = []\n",
    "for code in code_list:\n",
    "    # df = _U.get_stock_data(code, start_date='2021-11-3', end_date='2021-11-5')\n",
    "    df = pd.read_csv(f'{folder_path}/{code}.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df[(df['datetime'] >= '2021-11-3 00:00:00') & (df['datetime'] <= '2021-11-5 23:59:59')]  \n",
    "    \n",
    "    # generate new features, labels\n",
    "    # rolling window for each entry\n",
    "    df = calc_new_features(df)\n",
    "    df = calc_labels(df)\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for i in tqdm.tqdm(range(len(df) - (REC_CNT + PRED_CNT))):\n",
    "        single_X, single_y = single_entry_gen(df.iloc[i:i + REC_CNT])\n",
    "        X_list.append(single_X)\n",
    "        y_list.append(single_y)\n",
    "    X_df = pd.DataFrame(X_list)\n",
    "    y_df = pd.DataFrame(y_list)\n",
    "    \n",
    "    # rename columns for X_df, y_df\n",
    "    used_cols = []\n",
    "    for level in range(1, 6):\n",
    "        used_cols.append(f'BidPr{level}')\n",
    "        used_cols.append(f'BidVol{level}')\n",
    "        used_cols.append(f'AskPr{level}')\n",
    "        used_cols.append(f'AskVol{level}')\n",
    "    col_list = []\n",
    "    for i in range(1, REC_CNT):\n",
    "        for col in used_cols:\n",
    "            col_list.append(f'{col}_lag{i}')\n",
    "    # print(f'X cols: {used_cols + col_list}')\n",
    "    if len(X_df) == 0:\n",
    "        print(f'{code}.csv empty.')\n",
    "        continue\n",
    "    if len(X_df.columns) != len(used_cols + col_list):\n",
    "        raise ValueError(f'X_df columns length mismatch: {len(X_df.columns)} != {len(used_cols + col_list)}')\n",
    "    X_df.columns = used_cols + col_list\n",
    "    y_df.columns = ['label']\n",
    "    \n",
    "    X_df_list.append(X_df)\n",
    "    y_df_list.append(y_df)\n",
    "    print(f'{code}.csv loaded.')\n",
    "    \n",
    "test_X_df = pd.concat(X_df_list, axis=0)\n",
    "test_y_df = pd.concat(y_df_list, axis=0)\n",
    "test_X_df.dropna(axis=0, inplace=True)\n",
    "test_y_df.dropna(axis=0, inplace=True)\n",
    "test_X_df.reset_index(drop=True, inplace=True)\n",
    "test_y_df.reset_index(drop=True, inplace=True)\n",
    "test_X_df.shape, test_y_df.shape, test_y_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to csv\n",
    "train_X_df.to_csv('train_X.csv', index=False)\n",
    "train_y_df.to_csv('train_y.csv', index=False)\n",
    "test_X_df.to_csv('test_X.csv', index=False)\n",
    "test_y_df.to_csv('test_y.csv', index=False)\n",
    "# 2d-train, 3d-test, saving\n",
    "# total time cost: 18m + 27.5m + 3.3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data from csv\n",
    "# train_X_df = pd.read_csv('train_X.csv')\n",
    "# train_y_df = pd.read_csv('train_y.csv')\n",
    "# test_X_df = pd.read_csv('test_X.csv')\n",
    "# test_y_df = pd.read_csv('test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458928, 200), (458928, 1), (695941, 200), (695941, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.shape, train_y_df.shape, test_X_df.shape, test_y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化\n",
    "\n",
    "def create_scalers(train_df, prefixes):\n",
    "    \"\"\"为多个特征前缀创建标准化器\"\"\"\n",
    "    scalers = {}\n",
    "    for prefix in prefixes:\n",
    "        scalers[prefix] = {}\n",
    "        for level in range(1, 6):  # 假设有5档\n",
    "            cols = [f\"{prefix}{level}\"] + [f\"{prefix}{level}_lag{i}\" for i in range(1, 10)]\n",
    "            scaler = StandardScaler().fit(train_df[cols])\n",
    "            scalers[prefix][level] = scaler\n",
    "    return scalers\n",
    "\n",
    "def apply_full_scaling(df, scalers):\n",
    "    \"\"\"应用标准化并合并所有特征\"\"\"\n",
    "    scaled_dfs = []\n",
    "    for prefix in scalers.keys():\n",
    "        for level in scalers[prefix].keys():\n",
    "            cols = [f\"{prefix}{level}\"] + [f\"{prefix}{level}_lag{i}\" for i in range(1, 10)]\n",
    "            scaled_data = scalers[prefix][level].transform(df[cols])\n",
    "            scaled_df = pd.DataFrame(scaled_data, columns=cols, index=df.index)\n",
    "            scaled_dfs.append(scaled_df)\n",
    "    return pd.concat(scaled_dfs, axis=1)\n",
    "\n",
    "# BidPr/BidVol/AskPr/AskVol统一处理\n",
    "all_prefixes = ['BidPr', 'BidVol', 'AskPr', 'AskVol']\n",
    "scalers = create_scalers(train_X_df, all_prefixes)\n",
    "train_X_scaled = apply_full_scaling(train_X_df, scalers)\n",
    "test_X_scaled = apply_full_scaling(test_X_df, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458928, 200), (458928, 1), (695941, 200), (695941, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_scaled.shape, train_y_df.shape, test_X_scaled.shape, test_y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 0    290941\n",
       " 1    167987\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 0    448511\n",
       " 1    247430\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_df['label'].value_counts(), test_y_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: (50000, 200), 测试集: (50000, 200)\n",
      "类别分布：\n",
      "Train: label\n",
      "0    25000\n",
      "1    25000\n",
      "Name: count, dtype: int64\n",
      "Test: label\n",
      "0    25000\n",
      "1    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 平衡数据集\n",
    "\n",
    "def create_balanced_dataset(X, y, sample_size=10000, random_state=42) :\n",
    "    \"\"\"\n",
    "    生成平衡的数据集\n",
    "    \"\"\"\n",
    "    # 平衡采样\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    each_class_size = sample_size // 2\n",
    "    sampled = []\n",
    "    for class_label in [0, 1]:\n",
    "        class_indices = y[y['label'] == class_label].index\n",
    "        n_samples = min(each_class_size, len(class_indices))\n",
    "        sampled.extend(np.random.choice(class_indices, n_samples, replace=False))\n",
    "    \n",
    "    # 划分数据集\n",
    "    X_balanced = X.loc[sampled]\n",
    "    y_balanced = y.loc[sampled]\n",
    "\n",
    "    return X_balanced, y_balanced\n",
    "        \n",
    "\n",
    "sample_size = 50000\n",
    "X_train_balanced, y_train_balanced = create_balanced_dataset(train_X_scaled, train_y_df, sample_size)\n",
    "X_test_balanced, y_test_balanced = create_balanced_dataset(test_X_scaled, test_y_df, sample_size)\n",
    "\n",
    "# 验证输出形状\n",
    "print(f\"训练集: {X_train_balanced.shape}, 测试集: {X_test_balanced.shape}\")\n",
    "print(\"类别分布：\")\n",
    "print(\"Train:\", y_train_balanced['label'].value_counts())\n",
    "print(\"Test:\", y_test_balanced['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression (SGD) ---\n",
      "Time elapsed:  2.310307025909424 (s)\n",
      "              precision   recall  f1-score      support\n",
      "0              0.743386  0.46756  0.574060  25000.00000\n",
      "1              0.611652  0.83860  0.707369  25000.00000\n",
      "accuracy       0.653080  0.65308  0.653080      0.65308\n",
      "macro avg      0.677519  0.65308  0.640714  50000.00000\n",
      "weighted avg   0.677519  0.65308  0.640714  50000.00000\n",
      "--- Linear SVM ---\n",
      "Time elapsed:  6.683095216751099 (s)\n",
      "              precision   recall  f1-score      support\n",
      "0              0.759179  0.43920  0.556471  25000.00000\n",
      "1              0.605482  0.86068  0.710871  25000.00000\n",
      "accuracy       0.649940  0.64994  0.649940      0.64994\n",
      "macro avg      0.682330  0.64994  0.633671  50000.00000\n",
      "weighted avg   0.682330  0.64994  0.633671  50000.00000\n",
      "--- XGBoost ---\n",
      "Time elapsed:  16.049792051315308 (s)\n",
      "              precision   recall  f1-score      support\n",
      "0              0.736806  0.63884  0.684335  25000.00000\n",
      "1              0.681224  0.77180  0.723689  25000.00000\n",
      "accuracy       0.705320  0.70532  0.705320      0.70532\n",
      "macro avg      0.709015  0.70532  0.704012  50000.00000\n",
      "weighted avg   0.709015  0.70532  0.704012  50000.00000\n",
      "--- MLP ---\n",
      "Time elapsed:  105.5001609325409 (s)\n",
      "              precision   recall  f1-score      support\n",
      "0              0.700389  0.61948  0.657455  25000.00000\n",
      "1              0.658886  0.73500  0.694865  25000.00000\n",
      "accuracy       0.677240  0.67724  0.677240      0.67724\n",
      "macro avg      0.679637  0.67724  0.676160  50000.00000\n",
      "weighted avg   0.679637  0.67724  0.676160  50000.00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.70532</td>\n",
       "      <td>0.681224</td>\n",
       "      <td>0.77180</td>\n",
       "      <td>0.723689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.64994</td>\n",
       "      <td>0.605482</td>\n",
       "      <td>0.86068</td>\n",
       "      <td>0.710871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (SGD)</th>\n",
       "      <td>0.65308</td>\n",
       "      <td>0.611652</td>\n",
       "      <td>0.83860</td>\n",
       "      <td>0.707369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.67724</td>\n",
       "      <td>0.658886</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.694865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision   Recall        F1\n",
       "Model                                                            \n",
       "XGBoost                     0.70532   0.681224  0.77180  0.723689\n",
       "Linear SVM                  0.64994   0.605482  0.86068  0.710871\n",
       "Logistic Regression (SGD)   0.65308   0.611652  0.83860  0.707369\n",
       "MLP                         0.67724   0.658886  0.73500  0.694865"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型列表\n",
    "models = [\n",
    "    ('Logistic Regression (SGD)',\n",
    "    SGDClassifier(\n",
    "        loss='log_loss',\n",
    "        penalty='l2',\n",
    "        alpha=1e-4,          # 正则化参数\n",
    "        max_iter=1000, \n",
    "        tol=1e-3,\n",
    "        n_jobs=-1,              # 并行计算\n",
    "        random_state=42\n",
    "    )),\n",
    "\n",
    "    ('Linear SVM',\n",
    "    LinearSVC(\n",
    "        C=1.0,                  # 正则化参数\n",
    "        dual=False,             # 避免大数据集的求解问题\n",
    "        max_iter=2000,          # 迭代次数增加以防止收敛失败\n",
    "        tol=1e-4,\n",
    "        random_state=42\n",
    "    )),\n",
    "\n",
    "    ('XGBoost',\n",
    "    XGBClassifier(\n",
    "        objective='binary:logistic',  # 二分类问题\n",
    "        n_estimators=500,\n",
    "        # early_stopping_rounds=50,  # 早停\n",
    "        learning_rate=0.05, \n",
    "        max_depth=6, \n",
    "        subsample=0.8, \n",
    "        colsample_bytree=0.8, \n",
    "        tree_method='hist',           # 适用于中等数据\n",
    "        n_jobs=-1,                    # 并行加速\n",
    "        random_state=42\n",
    "    )),\n",
    "\n",
    "    ('MLP',\n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64), # 两层隐藏层，神经元数 128 → 64\n",
    "        activation='relu',            # ReLU 激活函数\n",
    "        solver='adam',                # Adam 优化\n",
    "        alpha=1e-4,                   # L2 正则化\n",
    "        batch_size=128,               # 小批量梯度下降\n",
    "        learning_rate_init=0.001,      # 学习率\n",
    "        max_iter=500,                 # 训练 500 轮\n",
    "        early_stopping=True,          # 提前停止，防止过拟合\n",
    "        n_iter_no_change=10,          # 10 轮无提升则停止\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "X_train = X_train_balanced.copy()\n",
    "y_train = np.squeeze(y_train_balanced)\n",
    "X_test = X_test_balanced.copy()\n",
    "y_test = np.squeeze(y_test_balanced)\n",
    "\n",
    "# 训练评估\n",
    "results = []\n",
    "for name, model in models:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    result = {\n",
    "        'Model': name,\n",
    "        'Accuracy': report['accuracy'],\n",
    "        'Precision': report['1']['precision'],\n",
    "        'Recall': report['1']['recall'],\n",
    "        'F1': report['1']['f1-score']\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Time elapsed: \", elapsed, \"(s)\")\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    print(report_df)\n",
    "    \n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.set_index('Model', inplace=True)\n",
    "result_df.sort_values('F1', ascending=False, inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_time = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "args = {\n",
    "    'Time': cur_time,\n",
    "    'REC_CNT': REC_CNT,\n",
    "    'PRED_CNT': PRED_CNT,\n",
    "    'IS_BINARY': IS_BINARY,\n",
    "    'stock_cnt': len(code_list),\n",
    "    'sample_size': sample_size,\n",
    "    'train_start': '2021-11-1 00:00:00',\n",
    "    'train_end': '2021-11-2 23:59:59',\n",
    "    'test_start': '2021-11-3 00:00:00',\n",
    "    'test_end': '2021-11-5 23:59:59'\n",
    "}\n",
    "result_df = pd.concat([pd.Series(args), result_df])\n",
    "result_df.to_csv(f'results_{cur_time}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lob_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
